# 尝试探索的模型

## 1.简单/可解释性高模型 (Easy & Interpretable)

|模型类别|模型名称|预期表现|核心调优参数|在此数据集上的价值|
|-------|--------|--------|----------|----------------|
|1. 线性模型|线性回归 (Linear Regression)|性能最差，因为 M 的计算公式是非线性的。|无（作为纯基线）基线： 设定性能下限。|其低 R2 分数将证明非线性模型的重要性。
|2. 正则化线性模型|岭回归 (Ridge) / Lasso 回归|略优于线性回归，但提升有限。|alpha (正则化强度)|特征选择： Lasso 可以将不重要的动量特征的系数降为零，帮助识别最关键的特征。
|3. 非线性核模型|"K 近邻 (K-Nearest Neighbors, KNN)"|性能中等，对特征尺度敏感。|n_neighbors (邻居数), weights (权重方式)|距离敏感性： 展示标准化/归一化对模型的重要性。

## 2.中等/基于树的模型 (Intermediate & Tree-Based)

|模型类别|模型名称|预期表现|核心调优参数|在此数据集上的价值|
|-------|--------|--------|----------|----------------|
|4. 单树模型|决策树回归 (Decision Tree)|易过拟合，但能捕捉单个非线性路径。|max_depth, min_samples_split|可解释性： 绘制单棵树，直观展示模型如何根据 E1 或 E2 进行分割。|
|5. 集成/Bagging|随机森林 (Random Forest)|性能优异，比单树稳定得多，不易过拟合。|n_estimators (树的数量), max_depth|泛化能力： 建立一个强大的中等基线，其性能是后续复杂模型的主要参照。|

## 3.复杂/最优化模型 (Complex & Optimization-Focused)

|模型类别|模型名称|预期表现|核心调优参数|在此数据集上的价值|
|-------|--------|--------|----------|----------------|
|6. 集成/Boosting|"梯度提升树 (Gradient Boosting, e.g., XGBoost, LightGBM)"|最佳性能候选。擅长处理复杂的非线性关系。|"n_estimators, max_depth, learning_rate, subsample"|性能探索： 通过调整学习率和树的数量，完美演示偏差-方差权衡。|
|7. 非线性核模型|支持向量回归 (SVR)|训练速度慢，但对于小数据集性能好。|C (正则化参数), gamma (核函数参数), kernel|另类视角： 了解基于核函数的模型如何处理数据，以及它对标准化有多敏感。|
|8. 深度学习|全连接神经网络 (ANN / MLP)|最终性能最优解。但需要大量调优和合适的优化器。|hidden_layers, neurons, activation, optimizer, learning_rate|优化器与可视化： 完美展示不同优化器（SGD, Adam, RMSprop）和学习率如何影响训练损失曲线。|